"""
nuplandb models, schema version: 3.0, code generated by schema_gen.py.
DO NOT MODIFY THIS FILE UNLESS YOU KNOW WHAT YOU ARE DOING!
"""
from __future__ import annotations  # postpone evaluation of annotations

import bisect
import logging
import os.path as osp
from typing import Any, BinaryIO, Dict, List, NamedTuple, Optional, Sequence, Set, Tuple

import cv2
import geopandas as gpd
import matplotlib.pyplot as plt
import numpy as np
import numpy.typing as npt
import PIL
from cachetools import LRUCache, cached
from cachetools.keys import hashkey
from matplotlib.axes import Axes
from nuplan.common.actor_state.agent import Agent, AgentType
from nuplan.common.actor_state.oriented_box import OrientedBox
from nuplan.common.actor_state.state_representation import StateSE2, StateVector2D
from nuplan.database.utils.label.label import Label
from nuplan.database.common import data_types, sql_types
from nuplan.database.common.db import Table
from nuplan.database.common.utils import default_color, default_color_np, simple_repr
from nuplan.database.maps_db.layer import MapLayer
from nuplan.database.maps_db.utils import build_lane_segments_from_blps, connect_blp_predecessor, connect_blp_successor
from nuplan.database.nuplan_db.frame import Frame
from nuplan.database.nuplan_db.utils import crop_rect, get_boxes, get_candidates, get_future_box_sequence, \
    pack_future_boxes, render_on_map
from nuplan.database.utils.boxes.box3d import Box3D, BoxVisibility, box_in_image
from nuplan.database.utils.geometry import quaternion_yaw, view_points
from nuplan.database.utils.label.utils import local2agent_type, raw_mapping
from nuplan.database.utils.pointclouds.lidar import LidarPointCloud
from pyquaternion import Quaternion
from scipy import ndimage
from scipy.spatial.transform import Rotation as R
from sqlalchemy import Column, func, inspect
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from sqlalchemy.schema import ForeignKey
from sqlalchemy.types import Boolean, Float, Integer, PickleType, String, Text

__all__ = ['Category', 'Log', 'Camera', 'Lidar', 'EgoPose', 'Image', 'LidarPc', 'Track', 'LidarBox',
           'Scene', 'ScenarioTag', 'TrafficLightStatus']

Base = declarative_base()

MICROSECONDS_IN_A_SECOND = 1000000
LRU_CACHE_SIZE = 20480

logger = logging.getLogger()


class Category(Base):  # type: ignore
    """
    A category within our taxonomy. Includes both things (e.g. cars) or stuff (e.g. lanes, sidewalks).
    Subcategories are delineated by a period.
    """
    __tablename__ = "category"

    token = Column(sql_types.UUID, primary_key=True)  # type: str
    name = Column(String(64))  # type: str
    description = Column(Text)  # type: str

    tracks = relationship("Track", foreign_keys="Track.category_token",
                          back_populates="category")  # type: List[Track]

    @property
    def table(self) -> Table[Category]:
        """
        Get the category table.

        self._table is injected at runtime:
          db = self._table.db                   # get db instance
          session = self._table.db.session      # get session instance
        :return: The category table.
        """
        return self._table  # type: ignore

    def __repr__(self) -> str:
        """
        Return the string representation.
        :return: The string representation.
        """
        desc: str = simple_repr(self)
        return desc

    @property
    def color(self) -> Tuple[int, int, int]:
        """
        Get category color.
        :return: The category color tuple.
        """
        c: Tuple[int, int, int] = default_color(self.name)
        return c

    @property
    def color_np(self) -> npt.NDArray[np.float64]:
        """
        Get category color in numpy.
        :return: The category color in numpy.
        """
        c: npt.NDArray[np.float64] = default_color_np(self.name)
        return c


class Log(Base):  # type: ignore
    """
    Information about the log from which the data was extracted.
    """
    __tablename__ = "log"

    token = Column(sql_types.UUID, primary_key=True)  # type: str
    vehicle_name = Column(String(64))  # type: str
    vehicle_type = Column(String(64))  # type: str
    date = Column(String(64))  # type: str
    timestamp = Column(Integer)  # type: int
    logfile = Column(String(64))  # type: str
    location = Column(String(64))  # type: str
    map_version = Column(String(64))  # type: str

    cameras = relationship("Camera", foreign_keys="Camera.log_token", back_populates="log")  # type: List[Camera]
    ego_poses = relationship("EgoPose", foreign_keys="EgoPose.log_token", back_populates="log")  # type: List[EgoPose]
    lidars = relationship("Lidar", foreign_keys="Lidar.log_token", back_populates="log")  # type: List[Lidar]
    scenes = relationship("Scene", foreign_keys="Scene.log_token", back_populates="log")  # type: List[Scene]

    def map_layer(self, layer: str) -> MapLayer:
        """
        Get map layer by name.
        :param layer: The name of the map layer.
        :return: Map layer.
        """
        return self.table.db.maps_db.load_layer(self.map_version, layer)  # type: ignore

    def list_map_layers(self) -> None:
        """ List the name of all map layers. """
        logger.info(self.table.db.maps_db.layer_names(self.map_version))  # type: ignore

    def map_vector_layer(self, layer: str) -> gpd.geodataframe:
        """
        Get vector map layer by name.
        :param layer: The name of the vector map layer.
        :return: Vector map layer.
        """
        # TODO: Remove temporary workaround once map_version is cleaned
        map_version = self.map_version.replace('.gpkg', '')
        return self.table.db.maps_db.load_vector_layer(map_version, layer)  # type: ignore

    def list_map_vector_layers(self) -> Sequence[str]:
        """
        Get the name of all vector map layers.
        :return: The name of all vector map layers.
        """
        return self.table.db.maps_db.vector_layer_names(self.map_version)  # type: ignore

    @property
    def table(self) -> Table[Log]:
        """
        Get the log table.

        self._table is injected at runtime:
          db = self._table.db                   # get db instance
          session = self._table.db.session      # get session instance
        :return: The log table.
        """
        return self._table  # type: ignore

    @property
    def images(self) -> List[Image]:
        """
        Returns list of Images contained in the Log.
        :return: The list of Images contained in the log.
        """
        log_images = []
        for camera in self.cameras:
            log_images.extend(camera.images)
        return log_images

    @property
    def lidar_pcs(self) -> List[LidarPc]:
        """
        Returns list of Lidar PCs in the Log.
        :return: The list of Lidar PCs in the log.
        """
        log_lidar_pcs = []
        for lidar in self.lidars:
            log_lidar_pcs.extend(lidar.lidar_pcs)
        return log_lidar_pcs

    @property
    def lidar_boxes(self) -> List[LidarBox]:
        """
        Returns list of Lidar Boxes in the Log.
        :return: The list of Lidar Boxes in the log.
        """
        log_lidar_boxes = []
        for lidar_pc in self.lidar_pcs:
            log_lidar_boxes.extend(lidar_pc.lidar_boxes)
        return log_lidar_boxes

    def __repr__(self) -> str:
        """
        Return the string representation.
        :return: The string representation.
        """
        desc: str = simple_repr(self)
        return desc


class Camera(Base):  # type: ignore
    """
    Defines a calibrated camera used to record a particular log.
    """
    __tablename__ = "camera"

    token = Column(sql_types.UUID, primary_key=True)  # type: str
    log_token = Column(sql_types.UUID, ForeignKey("log.token"), nullable=False)  # type: str
    channel = Column(String(64))  # type: str
    model = Column(String(64))  # type: str
    translation = Column(sql_types.SqlTranslation)  # type: data_types.Translation
    rotation = Column(sql_types.SqlRotation)  # type: data_types.Rotation
    intrinsic = Column(sql_types.SqlCameraIntrinsic)  # type: data_types.CameraIntrinsic
    distortion = Column(PickleType)  # type: list[float]
    width = Column(Integer)  # type: int
    height = Column(Integer)  # type: int

    log = relationship("Log", foreign_keys=[log_token], back_populates="cameras")  # type: Log
    images = relationship("Image", foreign_keys="Image.camera_token", back_populates="camera")  # type: List[Image]

    @property
    def table(self) -> Table[Camera]:
        """
        Get the camera table.

        self._table is injected at runtime:
          db = self._table.db                   # get db instance
          session = self._table.db.session      # get session instance
        :return: The camera table.
        """
        return self._table  # type: ignore

    def __repr__(self) -> str:
        """
        Return the string representation.
        :return : The string representation.
        """
        desc: str = simple_repr(self)
        return desc

    @property
    def intrinsic_np(self) -> npt.NDArray[np.float64]:
        """
        Get the intrinsic in numpy format.
        :return: <np.float: 3, 3> Camera intrinsic.
        """
        return np.array(self.intrinsic)

    @property
    def distortion_np(self) -> npt.NDArray[np.float64]:
        """
        Get the distortion in numpy format.
        :return: <np.float: N> Camera distrotion.
        """
        return np.array(self.distortion)

    @property
    def translation_np(self) -> npt.NDArray[np.float64]:
        """
        Get the translation in numpy format.
        :return: <np.float: 3> Translation.
        """
        return np.array(self.translation)

    @property
    def quaternion(self) -> Quaternion:
        """
        Get the rotation in quaternion.
        :return: Rotation in quaternion.
        """
        return Quaternion(self.rotation)

    @property
    def trans_matrix(self) -> npt.NDArray[np.float64]:
        """
        Get the transformation matrix.
        :return: <np.float: 4, 4>. Transformation matrix.
        """
        tm: npt.NDArray[np.float64] = self.quaternion.transformation_matrix
        tm[:3, 3] = self.translation_np
        return tm

    @property
    def trans_matrix_inv(self) -> npt.NDArray[np.float64]:
        """
        Get the inverse transformation matrix.
        :return: <np.float: 4, 4>. Inverse transformation matrix.
        """
        tm: npt.NDArray[np.float64] = np.eye(4)
        rot_inv = self.quaternion.rotation_matrix.T
        tm[:3, :3] = rot_inv
        tm[:3, 3] = rot_inv.dot(np.transpose(-self.translation_np))
        return tm


class Lidar(Base):  # type: ignore
    """
    Defines a calibrated lidar used to record a particular log.
    """
    __tablename__ = "lidar"

    token = Column(sql_types.UUID, primary_key=True)  # type: str
    log_token = Column(sql_types.UUID, ForeignKey("log.token"), nullable=False)  # type: str
    channel = Column(String(64))  # type: str
    model = Column(String(64))  # type: str
    translation = Column(sql_types.SqlTranslation)  # type: data_types.Translation
    rotation = Column(sql_types.SqlRotation)  # type: data_types.Rotation
    max_nbr_points = Column(Integer)  # type: int

    log = relationship("Log", foreign_keys=[log_token], back_populates="lidars")  # type: Log
    lidar_pcs = relationship("LidarPc", foreign_keys="LidarPc.lidar_token",
                             back_populates="lidar")  # type: List[LidarPc]

    @property
    def table(self) -> Table[Lidar]:
        """
        Get the lidar table.

        self._table is injected at runtime:
          db = self._table.db                   # get db instance
          session = self._table.db.session      # get session instance
        :return: The lidar table.
        """
        return self._table  # type: ignore

    def __repr__(self) -> str:
        """
        Return the string representation.
        :return: The string representation.
        """
        desc: str = simple_repr(self)
        return desc

    @property
    def translation_np(self) -> npt.NDArray[np.float64]:
        """
        Get the translation in numpy format.
        :return: <np.float: 3> Translation.
        """
        return np.array(self.translation)

    @property
    def quaternion(self) -> Quaternion:
        """
        Get the rotation in quaternion.
        :return: The rotation in quaternion.
        """
        return Quaternion(self.rotation)

    @property
    def trans_matrix(self) -> npt.NDArray[np.float64]:
        """
        Get the transformation matrix.
        :return: <np.float: 4, 4>. Transformation matrix.
        """
        tm: npt.NDArray[np.float64] = self.quaternion.transformation_matrix
        tm[:3, 3] = self.translation_np
        return tm

    @property
    def trans_matrix_inv(self) -> npt.NDArray[np.float64]:
        """
        Get the inverse transformation matrix.
        :return: <np.float: 4, 4>. Inverse transformation matrix.
        """
        tm: npt.NDArray[np.float64] = np.eye(4)
        rot_inv = self.quaternion.rotation_matrix.T
        tm[:3, :3] = rot_inv
        tm[:3, 3] = rot_inv.dot(np.transpose(-self.translation_np))
        return tm


class VectorMapNp(NamedTuple):
    """
    Vector map data structure, including:
        coords: <np.float: num_lane_segments, 2, 2>
            The (x, y) coordinates of the start and end point of the lane segments.
        multi_scale_connections: Dict of {scale: connections_of_scale}.
            Each connections_of_scale is represented by an array of <np.float: num_connections, 2>,
            and each column in the array is [from_lane_segment_idx, to_lane_segment_idx].
    """
    coords: npt.NDArray[np.float64]
    multi_scale_connections: Dict[int, npt.NDArray[np.float64]]

    def translate(self, translate: npt.NDArray[np.float64]) -> VectorMapNp:
        """
        Translate the vector map.

        :param translate: <np.float: 3,>. Translation in x, y, z.
        :return: Translated vector map.
        """
        coords = self.coords
        coords += translate[:2]
        return self._replace(coords=coords)

    def rotate(self, quaternion: Quaternion) -> VectorMapNp:
        """
        Rotate the vector map.

        :param quaternion: Rotation to apply.
        :return: Rotated vector map.
        """
        coords = self.coords
        # Flattern the first two dimensions to make the shape (num_lane_segments * 2, 2).
        num_lane_segments, _, _ = coords.shape
        coords = coords.reshape(num_lane_segments * 2, 2)
        # Add zeros to the z dimension to make them 3D points.
        coords = np.concatenate((coords, np.zeros_like(coords[:, 0:1])), axis=-1)  # type: ignore
        # Rotate.
        coords = np.dot(quaternion.rotation_matrix.astype(coords.dtype), coords)  # type: ignore
        # Remove the z dimension and reshape it back to (num_lane_segments, 2, 2).
        coords = coords[:, :2].reshape(num_lane_segments, 2, 2)
        return self._replace(coords=coords)

    def scale(self, scale: npt.NDArray[np.float64]) -> VectorMapNp:
        """
        Scale the vector map.

        :param scale: <np.float: 3,>. Scale in x, y, z.
        :return: Scaled vector map.
        """
        # Ignore the z dimension.
        coords = self.coords
        coords *= scale[:2]
        return self._replace(coords=coords)

    def xflip(self) -> VectorMapNp:
        """
        Flip the vector map along the X-axis.
        :return: Flipped vector map.
        """
        coords = self.coords
        coords[:, :, 0] *= -1
        return self._replace(coords=coords)

    def yflip(self) -> VectorMapNp:
        """
        Flip the vector map along the Y-axis.
        :return: Flipped vector map.
        """
        coords = self.coords
        coords[:, :, 1] *= -1
        return self._replace(coords=coords)


class EgoPose(Base):  # type: ignore
    """
    Ego vehicle pose at a particular timestamp. Given with respect to global coordinate system.
    """
    __tablename__ = "ego_pose"

    token = Column(sql_types.UUID, primary_key=True)  # type: str
    timestamp = Column(Integer)  # field type: int
    x = Column(Float)  # type: float
    y = Column(Float)  # type: float
    z = Column(Float)  # type: float
    qw: float = Column(Float)
    qx: float = Column(Float)
    qy: float = Column(Float)
    qz: float = Column(Float)
    vx = Column(Float)  # type: float
    vy = Column(Float)  # type: float
    vz = Column(Float)  # type: float
    acceleration_x = Column(Float)  # type: float
    acceleration_y = Column(Float)  # type: float
    acceleration_z = Column(Float)  # type: float
    angular_rate_x = Column(Float)  # type: float
    angular_rate_y = Column(Float)  # type: float
    angular_rate_z = Column(Float)  # type: float
    epsg = Column(Integer)  # type: int
    health = Column(Boolean)  # type: bool
    log_token = Column(sql_types.UUID, ForeignKey("log.token"), nullable=False)  # type: str

    image = relationship("Image", foreign_keys="Image.ego_pose_token",
                         back_populates="ego_pose", uselist=False)  # type: Image
    lidar_pc = relationship("LidarPc", foreign_keys="LidarPc.ego_pose_token",
                            back_populates="ego_pose", uselist=False)  # type: LidarPc
    log = relationship("Log", foreign_keys=[log_token], back_populates="ego_poses")  # type: Log
    scene = relationship("Scene", foreign_keys="Scene.goal_ego_pose_token",
                         back_populates="goal_ego_pose", uselist=True)  # type: List[Scene]

    @property
    def table(self) -> Table[EgoPose]:
        """
        Get the ego pose table.

        self._table is injected at runtime:
          db = self._table.db                   # get db instance
          session = self._table.db.session      # get session instance
        :return: The ego pose table.
        """
        return self._table  # type: ignore

    def __repr__(self) -> str:
        """
        Return the string representation.
        :return: The string representation.
        """
        desc: str = simple_repr(self)
        return desc

    @property
    def quaternion(self) -> Quaternion:
        """
        Get the orientation of ego vehicle as quaternion respect to global coordinate system.
        :return: The orientation in quaternion.
        """
        return Quaternion(self.qw, self.qx, self.qy, self.qz)

    @property
    def translation_np(self) -> npt.NDArray[np.float64]:
        """
        Position of ego vehicle respect to global coordinate system.
        :return: <np.float: 3> Translation.
        """
        return np.array([self.x, self.y, self.z])

    @property
    def trans_matrix(self) -> npt.NDArray[np.float64]:
        """
        Get the transformation matrix.
        :return: <np.float: 4, 4>. Transformation matrix.
        """
        tm: npt.NDArray[np.float64] = self.quaternion.transformation_matrix
        tm[:3, 3] = self.translation_np
        return tm

    @property
    def trans_matrix_inv(self) -> npt.NDArray[np.float64]:
        """
        Get the inverse transformation matrix.
        :return: <np.float: 4, 4>. Inverse transformation matrix.
        """
        tm: npt.NDArray[np.float64] = np.eye(4)
        rot_inv = self.quaternion.rotation_matrix.T
        tm[:3, :3] = rot_inv
        tm[:3, 3] = rot_inv.dot(np.transpose(-self.translation_np))
        return tm

    def rotate_2d_points2d_to_ego_vehicle_frame(self, points2d: npt.NDArray[np.float64]) -> npt.NDArray[np.float64]:
        """
        Rotate 2D points from global frame to ego-vehicle frame.
        :param points2d: <np.float: num_points, 2>. 2D points in global frame.
        :return: <np.float: num_points, 2>. 2D points rotated to ego-vehicle frame.
        """
        # Add zeros to the z dimension to make them 3D points.
        points3d = np.concatenate((points2d, np.zeros_like(points2d[:, 0:1])), axis=-1)  # type: ignore
        # We need to extract the rotation around the z-axis only. since we are cropping a 2D map.
        # Construct scipy rotation instance using the rotation matrix from quaternion.
        rotation = R.from_matrix(self.quaternion.rotation_matrix.T)
        # Extract the angle of rotation around z-axis from the rotation.
        ego_rotation_angle = rotation.as_euler('zxy', degrees=True)[0]
        # Construct scipy rotation instance using ego_rotation_angle.
        xy_rotation = R.from_euler('z', ego_rotation_angle, degrees=True)
        # Rotate the corner points of the desired map crop to align with ego pose.
        rotated_points3d = xy_rotation.apply(points3d)
        # Remove the z dimension.
        rotated_points2d: npt.NDArray[np.float64] = rotated_points3d[:, :2]
        return rotated_points2d

    def get_map_crop(self,
                     xrange: Tuple[float, float],
                     yrange: Tuple[float, float],
                     map_layer_name: str,
                     rotate_face_up: bool,
                     target_imsize_xy: Optional[Tuple[float, float]] = None) -> \
            Tuple[Optional[npt.NDArray[np.float64]], npt.NDArray[np.float64], Tuple[float, ...]]:
        """
        This function returns the crop of the map centered at the current ego-pose with the given xrange and yrange.
        :param xrange: The range in x direction in meters relative to the current ego-pose. Eg: (-60, 60]).
        :param yrange: The range in y direction in meters relative to the current ego-pose Eg: (-60, 60).
        :param map_layer_name: A relevant map layer. Eg: 'drivable_area' or 'intensity'.
        :param rotate_face_up: Boolean indicating whether to rotate the image face up with respect to ego-pose.
        :param target_imsize_xy: The target grid xy dimensions for the output array. The xy resolution in meters / grid
            may be scaled by zooming to the desired dimensions.
        :return: (map_crop, map_translation, map_scale). Where:
            map_crop: The desired crop of the map.
            map_translation: The translation in map coordinates from the origin to the ego-pose.
            map_scale: Map scale (inverse of the map precision). This will be a tuple specifying the zoom in both the x
                and y direction if the target_imsize_xy parameter was set, which causes the resolution to change.

            map_scale and map_translation are useful for transforming objects like pointcloud/boxes to the map_crop.
            Refer to render_on_map().
        """
        try:
            map_layer: Optional[MapLayer] = self.lidar_pc.log.map_layer(layer=map_layer_name)
        except ValueError:
            logger.debug("{} not found".format(map_layer_name))
            map_layer = None

        if map_layer is None:
            precision: float = 1

            def to_pixel_coords(x: float, y: float) -> Tuple[float, float]:
                """
                Get the image coordinates given the x-y coordinates of point. This implementation simply returns the
                same coordinates.
                :param x: Global x coordinate.
                :param y: Global y coordinate.
                :return: Pixel coordinates in map.
                """
                return x, y
        else:
            precision = map_layer.precision
            to_pixel_coords = map_layer.to_pixel_coords  # type: ignore

        map_scale: Tuple[float, ...] = (1.0 / precision, 1.0 / precision, 1.0)

        ego_translation = self.translation_np
        center_x, center_y = to_pixel_coords(ego_translation[0], ego_translation[1])
        center_x, center_y = int(center_x), int(center_y)

        top_left = int(xrange[0] * map_scale[0]), int(yrange[0] * map_scale[1])
        bottom_right = int(xrange[1] * map_scale[0]), int(yrange[1] * map_scale[1])

        # We need to extract the rotation around the z-axis only. since we are cropping a 2D map.
        # Construct scipy rotation instance using the rotation matrix from quaternion.
        rotation = R.from_matrix(self.quaternion.rotation_matrix.T)
        # Extract the angle of rotation around z-axis from the rotation.
        ego_rotation_angle = rotation.as_euler('zxy', degrees=True)[0]
        # Construct scipy rotation instance using ego_rotation_angle.

        xy_rotation = R.from_euler('z', ego_rotation_angle, degrees=True)

        map_rotate = 0

        # Rotate the corner points of the desired map crop to align with ego pose.
        rotated = xy_rotation.apply([[top_left[0], top_left[1], 0],
                                     [top_left[0], bottom_right[1], 0],
                                     [bottom_right[0], top_left[1], 0],
                                     [bottom_right[0], bottom_right[1], 0]
                                     ])[:, :2]

        # Construct minAreaRect using 4 corner points
        rect = cv2.minAreaRect(np.hstack([rotated[:, :1] + center_x, rotated[:, 1:] + center_y]).astype(int))
        rect_angle = rect[2]

        # Due to rounding error, the dimensions returned by cv2 may be off by 1, therefore it's better to manually
        # calculate the cropped dimensions instead of relying on the values returned by cv2 in rect[1]
        cropped_dimensions = np.array([map_scale[0] * (xrange[1] - xrange[0]), map_scale[1] * (yrange[1] - yrange[0])])
        rect = (rect[0], cropped_dimensions, rect_angle)

        # In OpenCV 4.4, the angle returned by cv2.minAreaRect is [-90,0). In OpenCV 4.5, the angle returned
        # appears to be [0, 90), though this isn't documented anywhere. To be compatible with both versions,
        # we adjust the angle to be [-90,0) if it isn't already.
        rect_angle = rect[2]
        cropped_dimensions = np.array([map_scale[0] * (xrange[1] - xrange[0]), map_scale[1] * (yrange[1] - yrange[0])])
        if rect_angle >= 0:
            rect = (rect[0], cropped_dimensions, rect_angle - 90)
        else:
            rect = (rect[0], cropped_dimensions, rect_angle)

        # We construct rect using cv2.minAreaRect, which takes only 4 unordered corner points, and can not consider
        # the angle of the required rect. The range of of 'angle' in cv2.minAreaRect is [-90,0).
        # A good explanation for the angle can be found at :
        # https://namkeenman.wordpress.com/2015/12/18/open-cv-determine-angle-of-rotatedrect-minarearect/
        # Hence, we have to manually rotate the map after cropping based on the initial rotation angle.
        if ego_rotation_angle < -90:
            map_rotate = -90
        if -90 < ego_rotation_angle < 0:
            map_rotate = 0
        if 0 < ego_rotation_angle < 90:
            map_rotate = 90
        if 90 < ego_rotation_angle < 180:
            map_rotate = 180

        if map_layer is None:
            map_crop = None
        else:
            # Crop the rect using minAreaRect.
            map_crop = crop_rect(map_layer.data, rect)
            # Rotate the cropped map using adjusted angles,
            # since the angle is reset in cv2.minAreaRect every 90 degrees.
            map_crop = ndimage.rotate(map_crop, map_rotate, reshape=False)

            if rotate_face_up:
                # The map_crop is aligned with the ego_pose, but ego_pose is facing towards the right of the canvas,
                # but we need ego_pose to be facing up, hence rotating an extra 90 degrees.
                map_crop = np.rot90(map_crop)  # type: ignore

        # These are in units of pixels, where x points to the right and y points *down*.
        if map_layer is None:
            map_upper_left_offset_from_global_coordinate_origin = np.zeros((2,))
        else:
            map_upper_left_offset_from_global_coordinate_origin = np.array([-map_layer.transform_matrix[0, -1],
                                                                            map_layer.transform_matrix[1, -1]])

        ego_offset_from_map_upper_left = np.array([center_x, -center_y])
        crop_upper_left_offset_from_ego = np.array([xrange[0] * map_scale[0], yrange[0] * map_scale[1]])
        map_translation: npt.NDArray[np.float64] = (-map_upper_left_offset_from_global_coordinate_origin -
                                                    ego_offset_from_map_upper_left -
                                                    crop_upper_left_offset_from_ego)
        map_translation_with_z = np.array([map_translation[0], map_translation[1], 0])  # add z-coordinate

        if target_imsize_xy is not None:
            zoom_size_x = target_imsize_xy[0] / cropped_dimensions[0]
            zoom_size_y = target_imsize_xy[1] / cropped_dimensions[1]
            map_crop = ndimage.zoom(map_crop, [zoom_size_x, zoom_size_y])
            map_scale = (zoom_size_x, zoom_size_y)

        return map_crop, map_translation_with_z, map_scale

    def get_vector_map(
            self,
            xrange: Tuple[float, float],
            yrange: Tuple[float, float],
            connection_scales: Optional[List[int]] = None,
    ) -> VectorMapNp:
        """
        This function returns the crop of baseline paths (blps) map centered at the current ego-pose with
        the given xrange and yrange.

        :param xrange: The range in x direction in meters relative to the current ego-pose. Eg: [-60, 60].
        :param yrange: The range in y direction in meters relative to the current ego-pose Eg: [-60, 60].
        :param connection_scales: Connection scales to generate. Use the 1-hop connections if it's left empty.
        :return: Vector map data including lane segment coordinates and connections within the given range.
        """
        # load geopandas data
        blps_gdf = self.lidar_pc.log.map_vector_layer('baseline_paths')
        lane_poly_gdf = self.lidar_pc.log.map_vector_layer('lanes_polygons')
        intersections_gdf = self.lidar_pc.log.map_vector_layer('intersections')
        lane_connectors_gdf = self.lidar_pc.log.map_vector_layer('lane_connectors')
        lane_groups_gdf = self.lidar_pc.log.map_vector_layer('lane_groups_polygons')

        if (blps_gdf is None) or (lane_poly_gdf is None) or (intersections_gdf is None) or \
                (lane_connectors_gdf is None) or (lane_groups_gdf is None):
            # This sample has no vector map.
            coords = np.empty([0, 2, 2], dtype=np.float32)
            if not connection_scales:
                # Use the 1-hop connections if connection_scales is not specified.
                connection_scales = [1]
            multi_scale_connections = {
                scale: np.empty([0, 2], dtype=np.int64)
                for scale in connection_scales
            }
            return VectorMapNp(
                coords=coords,
                multi_scale_connections=multi_scale_connections,
            )

        # data enhancement
        blps_in_lanes = blps_gdf[blps_gdf['lane_fid'].notna()]
        blps_in_intersections = blps_gdf[blps_gdf['lane_connector_fid'].notna()]

        # enhance blps_in_lanes
        lane_group_info = lane_poly_gdf[['lane_fid', 'lane_group_fid']]
        blps_in_lanes = blps_in_lanes.merge(lane_group_info, on='lane_fid', how='outer')

        # enhance blps_in_intersections
        lane_connectors_gdf['lane_connector_fid'] = lane_connectors_gdf['fid']
        lane_conns_info = lane_connectors_gdf[
            ['lane_connector_fid', 'intersection_fid', 'exit_lane_fid', 'entry_lane_fid']]
        # Convert the exit_fid field of both data frames to the same dtype for merging.
        lane_conns_info = lane_conns_info.astype({'lane_connector_fid': int})
        blps_in_intersections = blps_in_intersections.astype({'lane_connector_fid': int})
        blps_in_intersections = blps_in_intersections.merge(lane_conns_info, on='lane_connector_fid', how='outer')

        # enhance blps_connection info
        lane_blps_info = blps_in_lanes[['fid', 'lane_fid']]
        from_blps_info = lane_blps_info.rename(columns={'fid': 'from_blp', 'lane_fid': 'exit_lane_fid'})
        to_blps_info = lane_blps_info.rename(columns={'fid': 'to_blp', 'lane_fid': 'entry_lane_fid'})
        blps_in_intersections = blps_in_intersections.merge(from_blps_info, on='exit_lane_fid', how='inner')
        blps_in_intersections = blps_in_intersections.merge(to_blps_info, on='entry_lane_fid', how='inner')

        # Select in-range blps
        candidate_lane_groups, candidate_intersections = get_candidates(
            self.translation_np, xrange, yrange, lane_groups_gdf, intersections_gdf)
        candidate_blps_in_lanes = blps_in_lanes[blps_in_lanes['lane_group_fid'].isin(
            candidate_lane_groups['fid'].astype(int))]
        candidate_blps_in_intersections = blps_in_intersections[blps_in_intersections['intersection_fid'].isin(
            candidate_intersections['fid'].astype(int))]

        ls_coordinates_list: List[List[List[float]]] = []
        ls_connections_list: List[List[int]] = []
        cross_blp_connection: Dict[str, List[int]] = dict()

        # generate lane_segments from blps in lanes
        build_lane_segments_from_blps(candidate_blps_in_lanes, ls_coordinates_list,
                                      ls_connections_list, cross_blp_connection)
        # generate lane_segments from blps in intersections
        build_lane_segments_from_blps(candidate_blps_in_intersections, ls_coordinates_list,
                                      ls_connections_list, cross_blp_connection)

        # generate connections between blps
        for blp_id, blp_info in cross_blp_connection.items():
            # Add predecessors
            connect_blp_predecessor(blp_id, candidate_blps_in_intersections, cross_blp_connection, ls_connections_list)
            # Add successors
            connect_blp_successor(blp_id, candidate_blps_in_intersections, cross_blp_connection, ls_connections_list)

        ls_coordinates = np.asarray(ls_coordinates_list, self.translation_np.dtype)
        ls_connections = np.asarray(ls_connections_list, np.int64)
        # Transform the lane coordinates from global frame to ego vehicle frame.
        # Flatten ls_coordinates from (num_ls, 2, 2) to (num_ls * 2, 2) for easier processing.
        ls_coordinates = ls_coordinates.reshape(-1, 2)
        ls_coordinates = ls_coordinates - self.translation_np[:2]
        ls_coordinates = self.rotate_2d_points2d_to_ego_vehicle_frame(ls_coordinates)
        ls_coordinates = ls_coordinates.reshape(-1, 2, 2).astype(np.float32)

        if connection_scales:
            # Generate multi-scale connections.
            multi_scale_connections = generate_multi_scale_connections(ls_connections, connection_scales)
        else:
            # Use the 1-hop connections if connection_scales is not specified.
            multi_scale_connections = {1: ls_connections}

        return VectorMapNp(
            coords=ls_coordinates,
            multi_scale_connections=multi_scale_connections,
        )


def generate_multi_scale_connections(connections: npt.NDArray[np.float64], scales: List[int]) -> \
        Dict[int, npt.NDArray[np.float64]]:
    """
    Generate multi-scale connections by finding the neighors up to max(scales) hops away for each node.

    :param connections: <np.float: num_connections, 2>. 1-hop connections.
    :param scales: Connections scales to generate.
    :return: Multi-scale connections as a dict of {scale: connections_of_scale}.
    """
    # This dict will have format {node_idx: neighbor_dict},
    # where each neighbor_dict will have format {'i_hop_neighbors': set_of_i_hop_neighbors}.
    node_idx_to_neighbor_dict: Dict[int, Dict[str, Set[int]]] = {}

    # Initialize the data structure for each node with its 1-hop neighbors.
    for connection in connections:
        start_idx, end_idx = list(connection)
        if start_idx not in node_idx_to_neighbor_dict:
            node_idx_to_neighbor_dict[start_idx] = {'1_hop_neighbors': set()}
        if end_idx not in node_idx_to_neighbor_dict:
            node_idx_to_neighbor_dict[end_idx] = {'1_hop_neighbors': set()}
        node_idx_to_neighbor_dict[start_idx]['1_hop_neighbors'].add(end_idx)

    # Find the neighors up to max(scales) hops away for each node.
    for scale in range(2, max(scales) + 1):
        for neighbor_dict in node_idx_to_neighbor_dict.values():
            neighbor_dict[f'{scale}_hop_neighbors'] = set()
            for n_hop_neighbor in neighbor_dict[f'{scale - 1}_hop_neighbors']:
                for n_plus_1_hop_neighbor in node_idx_to_neighbor_dict[n_hop_neighbor]['1_hop_neighbors']:
                    neighbor_dict[f'{scale}_hop_neighbors'].add(n_plus_1_hop_neighbor)

    # Get the connections of each scale.
    multi_scale_connections = {}
    for scale in scales:
        scale_connections = []
        for node_idx, neighbor_dict in node_idx_to_neighbor_dict.items():
            for n_hop_neighbor in neighbor_dict[f'{scale}_hop_neighbors']:
                scale_connections.append([node_idx, n_hop_neighbor])
        multi_scale_connections[scale] = np.array(scale_connections)

    return multi_scale_connections


class Image(Base):  # type: ignore
    """
    An image.
    """
    __tablename__ = "image"

    token = Column(sql_types.UUID, primary_key=True)  # type: str
    next_token = Column(sql_types.UUID, ForeignKey("image.token"), nullable=True)  # type: str
    prev_token = Column(sql_types.UUID, ForeignKey("image.token"), nullable=True)  # type: str
    ego_pose_token = Column(sql_types.UUID, ForeignKey("ego_pose.token"), nullable=False)  # type: str
    camera_token = Column(sql_types.UUID, ForeignKey("camera.token"), nullable=False)  # type: str
    filename_jpg = Column(String(128))  # type: str
    timestamp = Column(Integer)  # type: int

    next = relationship("Image", foreign_keys=[next_token], remote_side=[token])  # type: Image
    prev = relationship("Image", foreign_keys=[prev_token], remote_side=[token])  # type: Image
    ego_pose = relationship("EgoPose", foreign_keys=[ego_pose_token], back_populates="image")  # type: EgoPose
    camera = relationship("Camera", foreign_keys=[camera_token], back_populates="images")  # type: Camera

    @property
    def table(self) -> Table[Image]:
        """
        Get the image table.

        self._table is injected at runtime:
          db = self._table.db                   # get db instance
          session = self._table.db.session      # get session instance
        :return: The image table.
        """
        return self._table  # type: ignore

    def __repr__(self) -> str:
        """
        Return the string representation.
        :return: The string representation.
        """
        desc: str = simple_repr(self)
        return desc

    @property
    def log(self) -> Log:
        """
        Returns the Log containing the image.
        :return: The log containing this image.
        """
        return self.camera.log

    def load_as(self, img_type: str) -> Any:
        """
        Loads the image as a desired type.
        :param img_type: Can be either 'pil' or 'np' or 'cv2'. If the img_type is cv2, the image is returned in BGR
            format, otherwise it is returned in RGB format.
        :return: The image.
        """
        assert img_type in ['pil', 'cv2', 'np']

        pil_img = PIL.Image.open(self.load_bytes_jpg())

        if img_type == 'pil':
            return pil_img
        elif img_type == 'np':
            return np.array(pil_img)
        else:
            return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

    @property
    def filename(self) -> str:
        """
        Get the file name.
        :return: The file name.
        """
        return self.filename_jpg

    def load_bytes_jpg(self) -> BinaryIO:
        """
        Returns the bytes of the jpg data for this image.
        :return: The image bytes.
        """
        blob: BinaryIO = self.table.db.load_blob(self.filename)
        return blob

    @property
    def path(self) -> str:
        """
        Get the path to image file.
        :return: The image file path.
        """
        self.load_bytes_jpg()
        return osp.join(self._table.db.data_root, self.filename)

    def boxes(self, frame: Frame = Frame.GLOBAL) -> List[Box3D]:
        """
        Loads all boxes associated with this Image record. Boxes are returned in the global frame by default.
        :param frame: Specify the frame in which the boxes will be returned.
        :return: List of boxes.
        """
        boxes: List[Box3D] = get_boxes(self, frame, self.ego_pose.trans_matrix_inv, self.camera.trans_matrix_inv)

        return boxes

    def future_or_past_ego_poses(self, number: int, mode: str, direction: str) -> List[EgoPose]:
        """
        Get n future or past vehicle poses. Note here the frequency of pose differs from frequency of Image.
        :param number: Number of poses to fetch or number of seconds of ego poses to fetch.
        :param mode: Either n_poses or n_seconds.
        :param direction: Future or past ego poses to fetch, could be 'prev' or 'next'.
        :return: List of up to n or n seconds future or past ego poses.
        """

        if direction == 'prev':
            if mode == 'n_poses':
                return self.table._session.query(EgoPose).filter(  # type: ignore
                    EgoPose.timestamp < self.ego_pose.timestamp, self.camera.log_token == EgoPose.log_token). \
                    order_by(EgoPose.timestamp.desc()).limit(number).all()
            elif mode == 'n_seconds':
                return self.table._session.query(EgoPose).filter(  # type: ignore
                    EgoPose.timestamp - self.ego_pose.timestamp < 0,
                    EgoPose.timestamp - self.ego_pose.timestamp >= -number * 1e6,
                    self.camera.log_token == EgoPose.log_token). \
                    order_by(EgoPose.timestamp.desc()).all()
            else:
                raise NotImplementedError('Only n_poses and n_seconds two modes are supported for now!')
        elif direction == 'next':
            if mode == 'n_poses':
                return self.table._session.query(EgoPose).filter(  # type: ignore
                    EgoPose.timestamp > self.ego_pose.timestamp, self.camera.log_token == EgoPose.log_token). \
                    order_by(EgoPose.timestamp.asc()).limit(number).all()
            elif mode == 'n_seconds':
                return self.table._session.query(EgoPose).filter(  # type: ignore
                    EgoPose.timestamp - self.ego_pose.timestamp > 0,
                    EgoPose.timestamp - self.ego_pose.timestamp <= number * 1e6,
                    self.camera.log_token == EgoPose.log_token). \
                    order_by(EgoPose.timestamp.asc()).all()
            else:
                raise NotImplementedError('Only n_poses and n_seconds two modes are supported!')
        else:
            raise ValueError('Only prev and next two directions are supported!')

    def render(self,
               with_3d_anns: bool = True,
               box_vis_level: BoxVisibility = BoxVisibility.ANY,
               ax: Optional[Axes] = None) -> None:
        """
        Render the image with all 3d and 2d annotations.
        :param with_3d_anns: Whether you want to render 3D boxes?
        :param box_vis_level: One of the enumerations of <BoxVisibility>.
        :param ax: Axes object or array of Axes objects.
        """

        if ax is None:
            _, ax = plt.subplots(1, 1, figsize=(9, 16))

        ax.imshow(self.load_as(img_type='pil'))

        if with_3d_anns:
            for box in self.boxes(Frame.SENSOR):

                # Get the LidarBox record with the same token as box.token
                ann_record = self.table.db.lidar_box[box.token]  # type: ignore

                c = ann_record.category.color_np
                color = c, c, np.array([0, 0, 0])

                if box_in_image(box, self.camera.intrinsic_np,
                                (self.camera.width, self.camera.height), vis_level=box_vis_level):
                    box.render(ax, view=self.camera.intrinsic_np, normalize=True,
                               colors=color)  # type: ignore

        ax.set_xlim(0, self.camera.width)
        ax.set_ylim(self.camera.height, 0)
        ax.set_title(self.camera.channel)


class LidarPc(Base):  # type: ignore
    """
    A lidar point cloud.
    """
    __tablename__ = "lidar_pc"

    token = Column(sql_types.UUID, primary_key=True)  # type: str
    next_token = Column(sql_types.UUID, ForeignKey("lidar_pc.token"), nullable=True)  # type: str
    prev_token = Column(sql_types.UUID, ForeignKey("lidar_pc.token"), nullable=True)  # type: str
    ego_pose_token = Column(sql_types.UUID, ForeignKey("ego_pose.token"), nullable=False)  # type: str
    lidar_token = Column(sql_types.UUID, ForeignKey("lidar.token"), nullable=False)  # type: str
    scene_token = Column(sql_types.UUID, ForeignKey("scene.token"), nullable=False)  # type: str
    filename = Column(String(128))  # type: str
    timestamp = Column(Integer)  # field type: int

    next = relationship("LidarPc", foreign_keys=[next_token], remote_side=[token])  # type: LidarPc
    prev = relationship("LidarPc", foreign_keys=[prev_token], remote_side=[token])  # type: LidarPc
    ego_pose = relationship("EgoPose", foreign_keys=[ego_pose_token], back_populates="lidar_pc")  # type: EgoPose
    lidar = relationship("Lidar", foreign_keys=[lidar_token], back_populates="lidar_pcs")  # type: Lidar
    scene = relationship("Scene", foreign_keys=[scene_token], back_populates="lidar_pcs")  # type: Scene
    lidar_boxes = relationship("LidarBox", foreign_keys="LidarBox.lidar_pc_token",
                               back_populates="lidar_pc")  # type:  List[LidarBox]
    scenario_tags = relationship("ScenarioTag", foreign_keys="ScenarioTag.lidar_pc_token",
                                 back_populates="lidar_pc")  # type:  List[ScenarioTag]
    traffic_lights = relationship("TrafficLightStatus", foreign_keys="TrafficLightStatus.lidar_pc_token",
                                  back_populates="lidar_pc")  # type: List[TrafficLightStatus]

    @property
    def table(self) -> Table[LidarPc]:
        """
        Get the lidar pc table.

        self._table is injected at runtime:
          db = self._table.db                   # get db instance
          session = self._table.db.session      # get session instance
        :return: The lidar pc table.
        """
        return self._table  # type: ignore

    def __repr__(self) -> str:
        """
        Get the string representation.
        :return: The string representation.
        """
        desc: str = simple_repr(self)
        return desc

    @property
    def log(self) -> Log:
        """
        Returns the Log containing the LidarPC.
        :return: The log containing the LidarPC.
        """
        return self.lidar.log

    def future_ego_pose(self) -> Optional[EgoPose]:
        """
        Get future ego poses.
        :return: Ego pose at next pointcloud if any.
        """
        if self.next is not None:
            return self.next.ego_pose
        return None

    def past_ego_pose(self) -> Optional[EgoPose]:
        """
        Get past ego poses.
        :return: Ego pose at previous pointcloud if any.
        """
        if self.prev is not None:
            return self.prev.ego_pose
        return None

    def future_or_past_ego_poses(self, number: int, mode: str, direction: str) -> List[EgoPose]:
        """
        Get n future or past vehicle poses. Note here the frequency of pose differs from frequency of LidarPc.
        :param number: Number of poses to fetch or number of seconds of ego poses to fetch.
        :param mode: Either n_poses or n_seconds.
        :param direction: Future or past ego poses to fetch, could be 'prev' or 'next'.
        :return: List of up to n or n seconds future or past ego poses.
        """
        if direction == 'prev':
            if mode == 'n_poses':
                return self.table._session.query(EgoPose).filter(  # type: ignore
                    EgoPose.timestamp < self.ego_pose.timestamp, self.lidar.log_token == EgoPose.log_token). \
                    order_by(EgoPose.timestamp.desc()).limit(number).all()
            elif mode == 'n_seconds':
                return self.table._session.query(EgoPose).filter(  # type: ignore
                    EgoPose.timestamp - self.ego_pose.timestamp < 0,
                    EgoPose.timestamp - self.ego_pose.timestamp >= -number * 1e6,
                    self.lidar.log_token == EgoPose.log_token). \
                    order_by(EgoPose.timestamp.desc()).all()
            else:
                raise ValueError(f"Unknown mode: {mode}.")
        elif direction == 'next':
            if mode == 'n_poses':
                return self.table._session.query(EgoPose).filter(  # type: ignore
                    EgoPose.timestamp > self.ego_pose.timestamp, self.lidar.log_token == EgoPose.log_token). \
                    order_by(EgoPose.timestamp.asc()).limit(number).all()
            elif mode == 'n_seconds':
                return self.table._session.query(EgoPose).filter(  # type: ignore
                    EgoPose.timestamp - self.ego_pose.timestamp > 0,
                    EgoPose.timestamp - self.ego_pose.timestamp <= number * 1e6,
                    self.lidar.log_token == EgoPose.log_token). \
                    order_by(EgoPose.timestamp.asc()).all()
            else:
                raise ValueError(f"Unknown mode: {mode}.")
        else:
            raise ValueError(f"Unknown direction: {direction}.")

    def load(self, remove_close: bool = True) -> LidarPointCloud:
        """
        Load a point cloud.
        :param remove_close: If true, remove nearby points, defaults to True.
        :return: Loaded point cloud.
        """
        if self.lidar.channel == 'MergedPointCloud':
            if self.filename.endswith('bin2'):
                return LidarPointCloud.from_buffer(self.load_bytes(), 'bin2')
            else:
                # load pcd file
                assert self.filename.endswith('pcd'), f'.pcd file is expected but get {self.filename}'
                return LidarPointCloud.from_buffer(self.load_bytes(), 'pcd')
        else:
            raise NotImplementedError

    def load_bytes(self) -> BinaryIO:
        """
        Load the point cloud in binary.
        :return: Point cloud bytes.
        """
        blob: BinaryIO = self.table.db.load_blob(self.filename)
        return blob

    @property
    def path(self) -> str:
        """
        Get the path to the point cloud file.
        :return: Point cloud file path.
        """
        self.load_bytes()
        return osp.join(self.table.db.data_root, self.filename)

    def boxes(self, frame: Frame = Frame.GLOBAL) -> List[Box3D]:
        """
        Loads all boxes associated with this LidarPc record. Boxes are returned in the global frame by default.
        :param frame: Specify the frame in which the boxes will be returned.
        :return: The list of boxes.
        """
        boxes: List[Box3D] = get_boxes(self, frame, self.ego_pose.trans_matrix_inv, self.lidar.trans_matrix_inv)

        return boxes

    def boxes_with_future_waypoints(self, future_horizon_len_s: float, future_interval_s: float,
                                    frame: Frame = Frame.GLOBAL) -> List[Box3D]:
        """
        Loads all boxes and future boxes associated with this LidarPc record. Boxes are returned in the global frame by
            default and annotations are sampled at a frequency of ~0.5 seconds.
        :param future_horizon_len_s: Timestep horizon of the future waypoints in seconds.
        :param future_interval_s: Timestep interval of the future waypoints in seconds.
        :param frame: Specify the frame in which the boxes will be returned.
        :return: List of boxes in sample data that includes box centers and orientations at future timesteps.
        """

        # Because the 6 sec sample could have a timestamp that is slightly larger than 6 sec (e.g., 6.0001 sec),
        # we need to read more samples to make sure the sequence includes all the timestamps in the horizon.
        TIMESTAMP_MARGIN_MS = 1e6
        future_horizon_len_ms = future_horizon_len_s * 1e6
        query = self.table._session.query(LidarPc). \
            filter(LidarPc.timestamp - self.timestamp >= 0,
                   LidarPc.timestamp - self.timestamp <= future_horizon_len_ms + TIMESTAMP_MARGIN_MS). \
            order_by(LidarPc.timestamp.asc()).all()
        lidar_pcs = [lidar_pc for lidar_pc in list(query)]

        track_token_2_box_sequence = get_future_box_sequence(
            lidar_pcs=lidar_pcs,
            frame=frame,
            future_horizon_len_s=future_horizon_len_s,
            future_interval_s=future_interval_s,
            trans_matrix_ego=self.ego_pose.trans_matrix_inv,
            trans_matrix_sensor=self.lidar.trans_matrix_inv
        )
        boxes_with_future_waypoints: List[Box3D] = pack_future_boxes(
            track_token_2_box_sequence=track_token_2_box_sequence,
            future_interval_s=future_interval_s,
            future_horizon_len_s=future_horizon_len_s
        )

        return boxes_with_future_waypoints

    def closest_image(self, camera_channels: Optional[List[str]] = None) -> List[Image]:
        """
        Find the closest images to LidarPc.
        :param camera_channels: List of image channels to find closest image of.
        :return: List of Images from the provided channels closest to LidarPc.
        """
        if camera_channels is None:
            camera_channels = ['CAM_F0', 'CAM_B0', 'CAM_L0', 'CAM_L1', 'CAM_R0', 'CAM_R1']

        imgs = []
        for channel in camera_channels:
            img = self.table.db.session.query(Image).join(Camera). \
                filter(Image.camera_token == Camera.token). \
                filter(Camera.channel == channel). \
                filter(Camera.log_token == self.lidar.log_token).order_by(func.abs(Image.timestamp - self.timestamp)). \
                first()
            imgs.append(img)

        return imgs

    def render(self,
               render_future_waypoints: bool = False,
               render_map_raster: bool = False,
               render_vector_map: bool = False,
               render_track_color: bool = False,
               render_future_ego_poses: bool = False,
               track_token: Optional[str] = None,
               with_anns: bool = True,
               axes_limit: float = 80.,
               ax: Axes = None) -> plt.axes:
        """
        Render the Lidar pointcloud with appropriate boxes and (optionally) the map raster.
        :param render_future_waypoints: Whether to render future waypoints.
        :param render_map_raster: Whether to render the map raster.
        :param render_vector_map: Whether to render the vector map.
        :param render_track_color: Whether to render the tracks with different random color.
        :param render_future_ego_poses: Whether to render future ego poses.
        :param track_token: Which instance to render, if it's None, render all the instances.
        :param with_anns: Whether you want to render the annotations?
        :param axes_limit: The range of Lidar pointcloud that will be rendered will be between
            (-axes_limit, axes_limit).
        :param ax: Axes object.
        :return: Axes object.
        """

        if ax is None:
            _, ax = plt.subplots(1, 1, figsize=(25, 25))

        if with_anns:
            if render_future_waypoints:
                DEFAULT_FUTURE_HORIZON_LEN_S = 6.0
                DEFAULT_FUTURE_INTERVAL_S = 0.5
                boxes = self.boxes_with_future_waypoints(
                    DEFAULT_FUTURE_HORIZON_LEN_S, DEFAULT_FUTURE_INTERVAL_S, Frame.SENSOR
                )
            else:
                boxes = self.boxes(Frame.SENSOR)
        else:
            boxes = []

        if render_future_ego_poses:
            DEFAULT_FUTURE_HORIZON_LEN_S = 6
            TIMESTAMP_MARGIN_S = 1
            ego_poses = self.future_or_past_ego_poses(DEFAULT_FUTURE_HORIZON_LEN_S + TIMESTAMP_MARGIN_S,
                                                      'n_seconds',
                                                      'next')
        else:
            ego_poses = [self.ego_pose]

        labelmap = {lid: Label(raw_mapping['id2local'][lid], raw_mapping['id2color'][lid])
                    for lid in raw_mapping['id2local'].keys()}

        render_on_map(
            lidarpc_rec=self,
            boxes_lidar=boxes,
            ego_poses=ego_poses,
            radius=axes_limit,
            ax=ax,
            labelmap=labelmap,
            render_map_raster=render_map_raster,
            render_vector_map=render_vector_map,
            track_token=track_token,
            with_random_color=render_track_color,
            render_future_ego_poses=render_future_ego_poses
        )

        plt.axis('equal')
        ax.set_title('PC {} from {} in {}'.format(self.token, self.lidar.channel, self.log.location))

        return ax


class LidarBox(Base):  # type: ignore
    """
    Lidar box from tracker.
    """
    __tablename__ = "lidar_box"

    token: str = Column(sql_types.UUID, primary_key=True)
    lidar_pc_token: str = Column(sql_types.UUID, ForeignKey("lidar_pc.token"), nullable=False)
    track_token: str = Column(sql_types.UUID, ForeignKey("track.token"))
    x: float = Column(Float)
    y: float = Column(Float)
    z: float = Column(Float)
    width: float = Column(Float)
    length: float = Column(Float)
    height: float = Column(Float)
    vx: float = Column(Float)
    vy: float = Column(Float)
    vz: float = Column(Float)
    roll: float = Column(Float)
    pitch: float = Column(Float)
    yaw: float = Column(Float)
    confidence: float = Column(Float)

    lidar_pc: LidarPc = relationship("LidarPc", foreign_keys=[lidar_pc_token], back_populates="lidar_boxes")
    track: Track = relationship("Track", foreign_keys=[track_token], back_populates="lidar_boxes")

    @property
    def table(self) -> Table[Track]:
        """
        Get the lidar box table.

        self._table is injected at runtime:
          db = self._table.db                   # get db instance
          session = self._table.db.session      # get session instance
        :return: The lidar box table.
        """
        return self._table  # type: ignore

    def __repr__(self) -> str:
        """
        Return the string representation.
        :return: The string representation.
        """
        desc: str = simple_repr(self)
        return desc

    @property
    def log(self) -> Log:
        """
        Returns the Log containing the LidarBox.
        :return: The log containing the lidar box.
        """
        return self.lidar_pc.log

    @property
    def category(self) -> Category:
        """
        Returns the Category of the LidarBox.
        :return: The category of the lidar box.
        """
        return self.track.category

    @property
    def timestamp(self) -> int:
        """
        Returns the timestamp of the LidarBox.
        :return: The timestamp of the lidar box.
        """
        return int(self.lidar_pc.timestamp)

    @property
    def distance_to_ego(self) -> float:
        """
        Returns the distance of detection from Ego Vehicle.
        :return: The distance to ego vehicle.
        """
        return float(np.sqrt((self.x - self.lidar_pc.ego_pose.x) ** 2 + (self.y - self.lidar_pc.ego_pose.y) ** 2))

    @property
    def size(self) -> List[float]:
        """
        Get the box size.
        :return: The box size.
        """
        return [self.width, self.length, self.height]

    @property
    def translation(self) -> List[float]:
        """
        Get the box location.
        :return: The box location.
        """
        return [self.x, self.y, self.z]

    @property
    def rotation(self) -> List[float]:
        """
        Get the box rotation in euler angles.
        :return: The box rotation in euler angles.
        """
        qx = Quaternion(axis=(1, 0, 0), radians=self.roll)
        qy = Quaternion(axis=(0, 1, 0), radians=self.pitch)
        qz = Quaternion(axis=(0, 0, 1), radians=self.yaw)

        return list(qx * qy * qz)

    @property
    def quaternion(self) -> Quaternion:
        """
        Get the box rotation in quaternion.
        :return: The box rotation in quaternion.
        """
        return Quaternion(self.rotation)

    @property
    def translation_np(self) -> npt.NDArray[np.float64]:
        """
        Get the box translation in numpy.
        :return: <np.float: 3> Translation.
        """
        return np.array(self.translation)

    @property
    def size_np(self) -> npt.NDArray[np.float64]:
        """
        Get the box size in numpy.
        :return: <np.float, 3> Width, length and height.
        """
        return np.array(self.size)

    @property
    def _session(self) -> Any:
        """
        Get the underlying session.
        :return: The underlying session.
        """
        return inspect(self).session

    @cached(  # type: ignore
        cache=LRUCache(maxsize=LRU_CACHE_SIZE), key=lambda self: hashkey(self.track_token)
    )
    def _get_box_items(self) -> Tuple[List[Integer], List[LidarBox]]:
        """
        Get all boxes along the track.
        :return: The list of timestamps and boxes along the track.
        """
        box_list: List[LidarBox] = self._session.query(LidarBox).filter(
            LidarBox.track_token == self.track_token).all()
        sorted_box_list = sorted(box_list, key=lambda x: x.timestamp)

        return [b.timestamp for b in sorted_box_list], sorted_box_list

    def _find_box(self, step: int = 0) -> Optional[LidarBox]:
        """
        Find the next box along the track with the given step.
        :param: step: The number of steps to look ahead, defaults to zero.
        :return: The found box if any.
        """
        timestamp_list, sorted_box_list = self._get_box_items()
        i = bisect.bisect_left(timestamp_list, self.timestamp)
        j = i + step
        if j < 0 or j >= len(sorted_box_list):
            return None

        return sorted_box_list[j]  # type: ignore

    @property
    def prev(self) -> Optional[LidarBox]:
        """
        Get the previous box along the track if any.
        :return: The previous box along the track if any.
        """
        return self._find_box(-1)

    @property
    def next(self) -> Optional[LidarBox]:
        """
        Get the next box along the track if any.
        :return: The next box along the track if any.
        """
        return self._find_box(1)

    def future_or_past_ego_poses(self, number: int, mode: str, direction: str) -> List[EgoPose]:
        """
        Get n future or past vehicle poses. Note here the frequency of pose differs from frequency of LidarBox.
        :param number: Number of poses to fetch or number of seconds of ego poses to fetch.
        :param mode: Either n_poses or n_seconds.
        :param direction: Future or past ego poses to fetch, could be 'prev' or 'next'.
        :return: List of up to n or n seconds future or past ego poses.
        """

        if direction == 'prev':
            if mode == 'n_poses':
                return self.table._session.query(EgoPose).filter(  # type: ignore
                    EgoPose.timestamp < self.lidar_pc.ego_pose.timestamp, self.lidar_pc.lidar.log_token ==
                    EgoPose.log_token).order_by(EgoPose.timestamp.desc()).limit(number).all()
            elif mode == 'n_seconds':
                return self.table._session.query(EgoPose).filter(  # type: ignore
                    EgoPose.timestamp - self.lidar_pc.ego_pose.timestamp < 0,
                    EgoPose.timestamp - self.lidar_pc.ego_pose.timestamp >= -number * 1e6,
                    self.lidar_pc.lidar.log_token == EgoPose.log_token). \
                    order_by(EgoPose.timestamp.desc()).all()
            else:
                raise ValueError(f"Unknown mode: {mode}.")
        elif direction == 'next':
            if mode == 'n_poses':
                return self.table._session.query(EgoPose).filter(  # type: ignore
                    EgoPose.timestamp > self.lidar_pc.ego_pose.timestamp, self.lidar_pc.lidar.log_token ==
                    EgoPose.log_token).order_by(EgoPose.timestamp.asc()).limit(number).all()
            elif mode == 'n_seconds':
                return self.table._session.query(EgoPose).filter(  # type: ignore
                    EgoPose.timestamp - self.lidar_pc.ego_pose.timestamp > 0,
                    EgoPose.timestamp - self.lidar_pc.ego_pose.timestamp <= number * 1e6,
                    self.lidar_pc.lidar.log_token == EgoPose.log_token). \
                    order_by(EgoPose.timestamp.asc()).all()
            else:
                raise ValueError(f"Unknown mode: {mode}.")
        else:
            raise ValueError(f"Unknown direction: {direction}.")

    def _temporal_neighbors(self) -> Tuple[LidarBox, LidarBox, bool, bool]:
        """
        Find temporal neighbors to calculate velocity and angular velocity.
        :return: The previous box, next box and their existences. If the previous or next box do not exist, they will
            be set to the current box itself.
        """

        has_prev = self.prev is not None
        has_next = self.next is not None

        if has_prev:
            prev_lidar_box = self.prev
        else:
            prev_lidar_box = self

        if has_next:
            next_lidar_box = self.next
        else:
            next_lidar_box = self

        return prev_lidar_box, next_lidar_box, has_prev, has_next  # type: ignore

    @property
    def velocity(self) -> npt.NDArray[np.float64]:
        """
        Estimate box velocity for a box.
        :return: The estimated box velocity of the box.
        """

        max_time_diff = 1.5
        prev_lidar_box, next_lidar_box, has_prev, has_next = self._temporal_neighbors()

        if not has_prev and not has_next:
            # Can't estimate velocity for a single annotation
            return np.array([np.nan, np.nan, np.nan])

        pos_next = np.array(next_lidar_box.translation)
        pos_prev = np.array(prev_lidar_box.translation)
        pos_diff: npt.NDArray[np.float64] = pos_next - pos_prev
        pos_diff[2] = 0  # We don't have robust localization in z. So set this to zero.

        time_next = 1e-6 * next_lidar_box.timestamp
        time_prev = 1e-6 * prev_lidar_box.timestamp
        time_diff = time_next - time_prev

        if has_next and has_prev:
            # If doing centered difference, allow for up to double the max_time_diff.
            max_time_diff *= 2

        if time_diff > max_time_diff:
            # If time_diff is too big, don't return an estimate.
            return np.array([np.nan, np.nan, np.nan])
        else:
            return pos_diff / time_diff

    @property
    def angular_velocity(self) -> float:
        """
        Estimate box angular velocity for a box.
        :return: The estimated box angular velocity of the box.
        """

        max_time_diff = 1.5
        prev_lidar_box, next_lidar_box, has_prev, has_next = self._temporal_neighbors()

        if not has_prev and not has_next:
            # Can't estimate angular velocity for a single annotation
            return np.nan

        time_next = 1e-6 * next_lidar_box.timestamp
        time_prev = 1e-6 * prev_lidar_box.timestamp
        time_diff = time_next - time_prev

        if has_next and has_prev:
            # If doing centered difference, allow for up to double the max_time_diff.
            max_time_diff *= 2

        if time_diff > max_time_diff:
            # If time_diff is too big, don't return an estimate.
            return np.nan
        else:
            # We currently only look at yaw
            yaw_diff = quaternion_yaw(next_lidar_box.quaternion) - quaternion_yaw(prev_lidar_box.quaternion)

            # Yaw in radians, in the range `[-pi, pi]`. Hence, raw yaw_diff is in tha range `[-2pi, 2pi]`
            # Assume all actors heading changes are small within `max_time_diff`, compensate the changes to [-pi, pi]
            if yaw_diff > np.pi:
                yaw_diff -= 2 * np.pi
            elif yaw_diff < -np.pi:
                yaw_diff += 2 * np.pi
            return float(yaw_diff / time_diff)

    def box(self) -> Box3D:
        """
        Get the Box3D representation of the box.
        :return: The box3d representation of the box.
        """
        label_local = raw_mapping['global2local'][self.category.name]
        label_int = raw_mapping['local2id'][label_local]
        return Box3D(
            center=self.translation,
            size=self.size,
            orientation=self.quaternion,
            token=self.token,
            label=label_int,
            track_token=self.track_token,
        )

    def agent(self) -> Agent:
        """
        Creates an Agent object
        """
        pose = StateSE2(self.translation[0], self.translation[1], quaternion_yaw(self.quaternion) + np.pi / 2)

        oriented_box = OrientedBox(pose, width=self.size[0], length=self.size[1], height=self.size[2])

        label_local = raw_mapping['global2local'][self.category.name]
        agent_type = AgentType[local2agent_type[label_local]]

        agent = Agent(
            token=self.token,
            agent_type=agent_type if agent_type is not None else AgentType.VEHICLE,
            oriented_box=oriented_box,
            velocity=StateVector2D(self.velocity[0], self.velocity[1]),
            predictions=[],
            angular_velocity=self.angular_velocity,
            track_token=self.track_token,
        )

        return agent

    def render(self, ax: Optional[List[Axes]] = None) -> None:
        """
        Render LidarBox on an image and a lidar.
        :param ax: Array of Axes objects.
        """

        if ax is None:
            fig, ax = plt.subplots(1, 2, figsize=(18, 9))

        pc = self.lidar_pc
        imgs = self.lidar_pc.closest_image()

        # Figure out which camera the object is visible in (may return nothing)
        found = False
        for img in imgs:
            cam = img.camera
            box = self.box()
            box.transform(img.ego_pose.trans_matrix_inv)  # Move box to ego vehicle coord system
            box.transform(cam.trans_matrix_inv)  # Move box to sensor coord system
            if box_in_image(box, cam.intrinsic_np, (cam.width, cam.height),
                            vis_level=BoxVisibility.ANY):
                found = True
                break  # Found an image that matches.

        assert found, "Could not find image where annotation is visible"

        # Get the color
        if not self.category:
            logger.error('Wrong 3d instance mapping', self)
            c: npt.NDArray[np.float64] = np.array([128, 0, 128]) / 255.0
        else:
            c = self.category.color_np

        color = c, c, np.array([0, 0, 0])

        # === CAMERA view ===
        ax[0].imshow(img.load_as(img_type='pil'))
        box.render(ax[0], view=img.camera.intrinsic_np, normalize=True, colors=color)  # type: ignore
        ax[0].set_title(img.camera.channel)
        ax[0].axis('off')
        ax[0].set_aspect('equal')

        # === LIDAR view ===
        box = self.box()  # Need to re-load box from the global coord-system.
        box.transform(pc.ego_pose.trans_matrix_inv)  # Move box to ego vehicle coord system
        box.transform(pc.lidar.trans_matrix_inv)  # Move box to sensor coord system

        view = np.eye(4)
        pc.load().render_height(ax[1], view=view)
        box.render(ax[1], view=view, colors=color)  # type: ignore

        corners = view_points(box.corners(), view, False)[:2, :]
        ax[1].set_xlim([np.amin(corners[0, :]) - 10, np.amax(corners[0, :]) + 10])
        ax[1].set_ylim([np.amin(corners[1, :]) - 10, np.amax(corners[1, :]) + 10])
        ax[1].axis('off')
        ax[1].set_aspect('equal')


class ScenarioTag(Base):  # type: ignore
    """
    Scenarios Tags for a scene.
    """
    __tablename__ = 'scenario_tag'

    token: str = Column(sql_types.UUID, primary_key=True)
    lidar_pc_token: str = Column(sql_types.UUID, ForeignKey("lidar_pc.token"), nullable=False)
    type: str = Column(Text)
    agent_track_token: str = Column(sql_types.UUID, ForeignKey("track.token"), nullable=False)
    map_object_id: int = Column(Integer)

    lidar_pc: LidarPc = relationship("LidarPc", foreign_keys=[lidar_pc_token], back_populates="scenario_tags")
    agent_track: Track = relationship("Track", foreign_keys=[agent_track_token], back_populates="scenario_tags")

    @property
    def table(self) -> Table[ScenarioTag]:
        """
        Get the scenario tag table.

        self._table is injected at runtime:
          db = self._table.db                   # get db instance
          session = self._table.db.session      # get session instance
        :return: The scenario tag table.
        """
        return self._table  # type: ignore

    def __repr__(self) -> str:
        """
        Get the string representation.
        :return: The string representation.
        """
        desc: str = simple_repr(self)
        return desc

    @property
    def _session(self) -> Any:
        """
        Get the underlying session.
        :return: The underlying session.
        """
        return inspect(self).session


class Track(Base):  # type: ignore
    """
    Track from tracker output. A track represents a bunch of lidar boxes with the same instance id in a given log.
    """
    __tablename__ = 'track'

    token: str = Column(sql_types.UUID, primary_key=True)
    category_token: str = Column(sql_types.UUID, ForeignKey("category.token"), nullable=False)
    width: float = Column(Float)
    length: float = Column(Float)
    height: float = Column(Float)
    confidence: float = Column(Float)

    lidar_boxes: List[LidarBox] = relationship("LidarBox", foreign_keys=[LidarBox.track_token],
                                               back_populates="track")
    category: Category = relationship("Category", foreign_keys=[category_token], back_populates="tracks")
    scenario_tags: List[ScenarioTag] = relationship("ScenarioTag", foreign_keys=[ScenarioTag.agent_track_token],
                                                    back_populates="agent_track")

    @property
    def table(self) -> Table[Track]:
        """
        Get the track table.

        self._table is injected at runtime:
          db = self._table.db                   # get db instance
          session = self._table.db.session      # get session instance
        :return: The track table.
        """
        return self._table  # type: ignore

    def __repr__(self) -> str:
        """
        Get the string representation.
        :return: The string representation.
        """
        desc: str = simple_repr(self)
        return desc

    @property
    def _session(self) -> Any:
        """
        Get the underlying session.
        :return: The underlying session.
        """
        return inspect(self).session

    @property
    def nbr_lidar_boxes(self) -> int:
        """
        Returns number of boxes in the Track.
        :return: Number of boxes.
        """
        return self._session.query(LidarBox).filter(LidarBox.track_token == self.token).count()  # type: ignore

    @property
    def first_lidar_box(self) -> LidarBox:
        """
        Returns first lidar box along the track.
        :return: First lidar box along the track.
        """
        return self._session.query(LidarBox).filter(  # type: ignore
            LidarBox.track_token == self.token).join(LidarPc). \
            order_by(LidarPc.timestamp.asc()).first()

    @property
    def last_lidar_box(self) -> LidarBox:
        """
        Returns last lidar box along the track.
        :return: Last lidar box along the track.
        """
        return self._session.query(LidarBox).filter(  # type: ignore
            LidarBox.track_token == self.token).join(LidarPc). \
            order_by(LidarPc.timestamp.desc()).first()

    @property
    def duration(self) -> int:
        """
        Returns duration of Track.
        :return: Duration of the track.
        """
        return self.last_lidar_box.timestamp - self.first_lidar_box.timestamp

    @property
    def distances_to_ego(self) -> npt.NDArray[np.float64]:
        """
        Returns array containing distances of all boxes in the Track from ego vehicle.
        :return: Distances of all boxes in the track from ego vehicle.
        """
        return np.asarray([lidar_box.distance_to_ego for lidar_box in self.lidar_boxes])

    @property
    def min_distance_to_ego(self) -> float:
        """
        Returns minimum distance of Track from Ego Vehicle.
        :return: The minimum distance of the track from ego vehicle.
        """
        return np.amin(self.distances_to_ego)  # type: ignore

    @property
    def max_distance_to_ego(self) -> float:
        """
        Returns maximum distance of Track from Ego Vehicle.
        :return: The maximum distance of the tack from ego vehicle.
        """
        return np.amax(self.distances_to_ego)  # type: ignore


class Scene(Base):  # type: ignore
    """
    Scenes in a Log.
    """
    __tablename__ = 'scene'

    token: str = Column(sql_types.UUID, primary_key=True)
    log_token: str = Column(sql_types.UUID, ForeignKey("log.token"), nullable=False)
    name: str = Column(Text)
    goal_ego_pose_token: str = Column(sql_types.UUID, ForeignKey("ego_pose.token"), nullable=True)

    log: Log = relationship("Log", foreign_keys=[log_token], back_populates="scenes")
    goal_ego_pose: EgoPose = relationship("EgoPose", foreign_keys=[goal_ego_pose_token], back_populates="scene")
    lidar_pcs: List[LidarPc] = relationship("LidarPc", foreign_keys=[LidarPc.scene_token], back_populates="scene")

    @property
    def table(self) -> Table[Scene]:
        """
        Get the scene table.

        self._table is injected at runtime:
          db = self._table.db                   # get db instance
          session = self._table.db.session      # get session instance
        :return: The scene table.
        """
        return self._table  # type: ignore

    def __repr__(self) -> str:
        """
        Get the string representation.
        :return: The string representation.
        """
        desc: str = simple_repr(self)
        return desc

    @property
    def _session(self) -> Any:
        """
        Get the underlying session.
        :return: The underlying session.
        """
        return inspect(self).session


class TrafficLightStatus(Base):  # type: ignore
    """
    Traffic Light Statuses in a Log.
    """
    __tablename__ = 'traffic_light_status'

    token: str = Column(sql_types.UUID, primary_key=True)
    lidar_pc_token: str = Column(sql_types.UUID, ForeignKey("lidar_pc.token"), nullable=False)
    stop_line_id: int = Column(Integer)
    lane_connector_id: int = Column(Integer)
    status: str = Column(String(8))

    lidar_pc: LidarPc = relationship("LidarPc", foreign_keys=[lidar_pc_token],
                                     back_populates="traffic_lights")

    @property
    def table(self) -> Table[TrafficLightStatus]:
        """
        Get the traffic light status table.

        self._table is injected at runtime:
          db = self._table.db                   # get db instance
          session = self._table.db.session      # get session instance
        :return: The traffic light status table.
        """
        return self._table  # type: ignore

    def __repr__(self) -> str:
        """
        Get the string representation.
        :return: The string representation.
        """
        desc: str = simple_repr(self)
        return desc

    @property
    def _session(self) -> Any:
        """
        Get the underlying session.
        :return: The underlying session.
        """
        return inspect(self).session
